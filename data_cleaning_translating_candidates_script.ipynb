{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7d316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from googletrans import Translator\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sparknlp\n",
    "from rake_nltk import Rake\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc4822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dryne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dryne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dryne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dryne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a73380",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=LAPTOP-KLLTOUUR\\SQLEXPRESS;'\n",
    "                      'Database=Dashboard;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()\n",
    "cursor2=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b025ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM AllCandidates\"\n",
    "\n",
    "cursor.execute(query)\n",
    "data = cursor.fetchall()\n",
    "\n",
    "columns = [column[0] for column in cursor.description]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for row in data:\n",
    "    df = pd.concat(\n",
    "        [df, pd.DataFrame([dict(zip(columns, row))])], ignore_index=True)\n",
    "\n",
    "df.to_excel(\"AllCandidates.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8277928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# translator = Translator(service_urls=['translate.google.com'])\n",
    "\n",
    "\n",
    "# # Function to translate text to English\n",
    "# def translate_text(text):\n",
    "#     translation = translator.translate(text, dest='en')\n",
    "#     return translation.text\n",
    "\n",
    "# # Apply translation to the DataFrame column\n",
    "# df[\"About\"] = df[\"About\"].apply(translate_text)\n",
    "# df[\"Title\"] = df[\"Title\"].apply(translate_text)\n",
    "# df[\"Experience\"]=df[\"Experience\"].apply(translate_text)\n",
    "# df[\"Education\"]=df[\"Education\"].apply(translate_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2955762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Defining KPIs.\n",
      "- Analysis and creation of KPIs using tableau and tableau prep.\n",
      "- a fake news detector and gold price predictor using machine learning techniques.\n",
      "Dec 2022 - Present · 6 mos\n",
      "Neopolis Development · Full-time\n",
      "- Implementation of all phases in a dashboard using ReactJS, Django, and Django rest framework.\n",
      "\n",
      "- Calculating measures.\n",
      "- Call center dashboard.\n",
      "- Work on Creative Canvas, BMC, SWOT\n",
      "Tunisia\n",
      "Tunis, Tunisia\n",
      "Skills:Docker Products · Gitlab · Linux · Django · Git · Python (Programming Language)\n",
      "CodeClause · Internship\n",
      "Skills:Flask · GitHub · Apprentissage automatique · Développement web · Python (langage de programmation) · HTML\n",
      "Aug 2022 - Oct 2022 · 3 mos\n",
      "FIDNESS · Internship\n",
      "- Diversity and inclusion dashboard.\n",
      "Skills: Leadership · Gestion du stress · Leadership d’équipe · Entrepreneuriat\n",
      "Skills: Flask · GitHub · Apprentissage automatique · Développement web · Python (langage de programmation) · HTML\n",
      "+2\n",
      "Capture.PNG\n",
      "Show all 7 experiences\n",
      "Skills: Docker Products · Gitlab · Linux · Django · Git · Python (Programming Language)\n",
      "End of study internship based on : \n",
      "Data scientist intern\n",
      "Feb 2022 - Jun 2022 · 5 mos\n",
      "Tunis, Tunisie\n",
      "Skills:Informatique décisionnelle · Indicateurs clés de performance · Microsoft Power BI · GitHub\n",
      "Oct 2022 - Nov 2022 · 2 mos\n",
      "Short-term internship at codeclause in the field of data science. The internship consists of developing: \n",
      "- Achieving the SDGs as the main goal of our philosophy\n",
      "- Customer retention dashboard.\n",
      "OST is a competition for college students and recent graduates to practice and learn entrepreneurial skills through a competition co-created by the Columbia School of Engineering and the School of Business.\n",
      "- Immerse yourself in the problem and see how the proposed idea can be implemented as a solution\n",
      "Skills:Leadership · Gestion du stress · Leadership d’équipe · Entrepreneuriat\n",
      "- Pitch\n",
      "virtual internship with pwc based on the creation of :\n",
      "Competitor\n",
      "Open Startup · Part-time\n",
      "Django Developer\n",
      "- Identify key competitors for the idea\n",
      "- Implementation of the vision\n",
      "- Create a unique value proposition\n",
      "Data Analytics virtual intern (forage)\n",
      "Nabeul, Tunisia · Hybrid\n",
      "- Customer interviews to identify key target consumers\n",
      "Data Science Intern\n",
      "PwC Switzerland · Internship\n",
      "Skills: Informatique décisionnelle · Indicateurs clés de performance · Microsoft Power BI · GitHub\n",
      "- Taking insights and actions.\n",
      "Skills: JSON Web Token (JWT) · Talend · expo · GitHub · Tableau · React Native · Django · Framework Django REST · Apprentissage automatique · API Google Maps · Développement web · Python (langage de programmation) · MySQL\n",
      "- Creation of a machine learning model to track the number of churns using python.\n",
      "Feb 2021 - Apr 2021 · 3 mos\n",
      "Experience\n",
      "Offer Letter.pdf\n",
      "- Development of a mobile geolocation system to track the number of visits for each partner using React Native, Django, and google maps APIs.\n",
      "Attestation de stage.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols_to_clean = [\"About\", \"Experience\", \"Education\",\n",
    "                 \"LicensesAndCertifications\", \"Skills\"]\n",
    "cols_to_tokenize = [\"Experience\", \"Education\",\n",
    "                    \"LicensesAndCertifications\", \"Skills\"]\n",
    "list_of_keywords=[\"about\",\"experience\",\"education\",\"licensesandcertifications\",\n",
    "                  \"licenses&certifications\",\"skills\",\"licensesetcertifications\"]\n",
    "list_to_clean_skills=[\"show\",\"by\",\"highly\",\"skilled\",\"ardhaoui\",\"who\",\"ardhaouiwho\",\"ardhaouihas\",\n",
    "                      \"all\",\"endorsement\",\"skills\",\"skill\",\"endorsements\",\"given\",\"an\",\"sep\",\"apr\",\"feb\",\"jul\",\"tunisia\",\n",
    "                      \"endorsed\",\"this\",\"aymen\",\"byaymen\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"neoxam\",\"time\",\"tunisie\"]\n",
    "clean_line_list=[\"skills:\",\"-\",\"->\"]\n",
    "list_year=[\"yr\",\"y\",\"yer\",\"yar\",\"yrs\"]\n",
    "list_mois=[\"mos\",\"ms\"]\n",
    "print(df[\"Experience\"][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82bb36c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def contains_stopword(string, stopwords):\n",
    "    words=string.split()\n",
    "    for word in stopwords:\n",
    "        if word in words  :\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#éliminer la redondance\n",
    "def remove_redundancy(liste):\n",
    "    if(len(liste) >= 2):\n",
    "        i = 0\n",
    "        while i < len(liste) - 1:\n",
    "            if liste[i] == liste[i + 1]:\n",
    "                liste.remove(liste[i + 1])\n",
    "            else:\n",
    "                i += 1\n",
    "    return liste\n",
    "def remove_keywords(liste):\n",
    "    if not liste:  # Check if the list is empty\n",
    "        return liste\n",
    "\n",
    "    # Removing keywords\n",
    "    first_word = liste[0]\n",
    "    liste2 = liste[1:] if first_word.lower() in list_of_keywords else liste\n",
    "    return liste2\n",
    "#replacer un mot dans une liste \n",
    "def replace_word_in_list(word_list, old_word, new_word):\n",
    "    for i in range(len(word_list)):\n",
    "        if word_list[i] == old_word:\n",
    "            word_list[i] = new_word\n",
    "            \n",
    "def clean_line(words):\n",
    "    cleaned_words = []\n",
    "   \n",
    "    \n",
    "    for word in words:\n",
    "        if word.lower() not in clean_line_list: \n",
    "            cleaned_words.append(word)\n",
    "    if cleaned_words:\n",
    "        premier=cleaned_words[0]\n",
    "        premier=premier.capitalize()\n",
    "        cleaned_words= cleaned_words[1:]\n",
    "        cleaned_words.insert(0, premier)\n",
    "    return cleaned_words\n",
    "\n",
    "    \n",
    "\n",
    "# nettoyer les données\n",
    "def clean_text(text, col):\n",
    "    \n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = text.lower()\n",
    "        text=text.replace(\":\",\" \")\n",
    "        text=text.replace(\"+\",\"-\")\n",
    "        text=text.replace(\"*\",\"-\")\n",
    "        text=text.replace(\">\",\"-\")\n",
    "        text = text.strip()\n",
    "        lines = text.splitlines()  # Split the text into lines to preserve original line breaks\n",
    "        cleaned_lines = []\n",
    "\n",
    "        for line in lines:\n",
    "            words = line.split()\n",
    "            words = remove_keywords(words)\n",
    "            words = remove_redundancy(words)\n",
    "\n",
    "            b = True  # Initialize 'b' here with default value True\n",
    "\n",
    "            if col == \"Skills\" or col == \"Experience\":\n",
    "                for i in range(len(words)):\n",
    "                    if contains_stopword(words[i], list_to_clean_skills) and words[i] not in cleaned_lines:\n",
    "                        b = False\n",
    "                        \n",
    "                    if words[i] in list_year:\n",
    "                        words[i] = 'year'\n",
    "                    elif words[i].lower() in list_mois:\n",
    "                        words[i] = 'month'\n",
    "            \n",
    "            if b:\n",
    "                cleaned_words = clean_line(words)\n",
    "                cleaned_lines.append(\" \".join(cleaned_words))  # Join the words with space\n",
    "\n",
    "        cleaned_text = \"\\n\".join(cleaned_lines)  # Join the lines using newline character\n",
    "        return cleaned_text\n",
    "\n",
    "   \n",
    " for col in cols_to_clean:\n",
    "    df[col] = df[col].apply(lambda x: clean_text(x, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02469ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-gestion et suivi des plans d'action issues des inspections des autorites competentes internes et externe.\n",
      "-lancement des bons d'approvisionnement\n",
      "Controle matiere premiere et produits finis.\n",
      "-realisation des audits externes ( fournisseurs / prestataires)\n",
      "-elaboration matrice / grille des profils des fonctions / des competences par categorie / par departement / par niveau de maitrise\n",
      "Pfa\n",
      "Assurance qualite\n",
      "-participation au preparatif des inspections externes\n",
      "-mise en place de la modalite de gestion des audits internes des la selection des auditeurs internes jusqu'a l'evaluation des auditeurs\n",
      "-gestion des commandes export des la planification jusqu'a l'expedition\n",
      "-mise en place de la politique de la gestion du personnel habilitation et formation continue, gestion des performances du personnel\n",
      "-redaction et verification des procedures et de tout document officiel du travail\n",
      "-maitrise des appareils danalyses hplc,spectrometrie ir, spectrometrie uv, ccm, dissolutest, potentiometre et karl-fischer.\n",
      "-gestion des kpi\n",
      "-veuille qualite bpf / bpl / bpd\n",
      "-revue du systeme qualite\n",
      "Poulina logo\n",
      "-veuille bpf sur terrain\n",
      "Medivet full-time\n",
      "-maitrise du logiciel qualipro ( des modules en relation avec les taches accordees )\n",
      "-gestion du systeme qualite capa, deviations, change control\n",
      "Stagiaire\n",
      "-mise en place des capa\n",
      "-controle des matieres premieres et des produits finis.\n",
      "-optimisation et validation des methodes d'analyse.\n",
      "-suivi des plannings d'etalonnage et des qualifications avec les prestataires\n",
      "-redaction des documents operationnels ( procedures, mode d'emploi des equipements dans un laboratoire, protocole de controle, ba .. )\n",
      "-formation du personnel sur le logiciel qualipro\n",
      "Faculte des sciences de tunis\n",
      "-mise en place du logiciel qualipro\n",
      "Projet de fin d'annee\n",
      "-elaboration / verification des fiches de fonctions / des fiches de postes / des organigrammes\n",
      "Le sujet essentiel de ce travail est les bio-materiaux .cet projet presente les ceramiques et la technique utilisee pour elaborer les ceramiques a base de phosphate de calcium. d'une part , cet projet presente les caracteristiques physico-chimiques de l'hydroxyapatite et le tcp (le phosphate tricalcique ) , leurs points communs , leurs differences et d'autre part il decrit les risques d'utilisation des ces derniers.\n",
      "Provital , poulina group holding\n",
      "-suivi des plannings de formations internes et externes\n",
      "Chimiste analyste\n",
      "-maitrise du logiciel empower.\n",
      "Etudiante stagiaire\n",
      "Neapolis pharma , groupe medis\n",
      "-lancement des of\n",
      "\n",
      "-gestion du stock refuse en termes de pointage & veille a la tracabilite sur sage x3\n",
      "-participation a des preparatifs des inspections sfda\n",
      "_elaboration et suivi des programmes de formations internes et externes\n",
      "Charge documentation, audit et competences\n",
      "Charge documentation, audit et competences\n",
      "-gestion des documents internes et externes\n",
      "-gestion des audits internes selection des auditeurs internes, elaboration du programme d'audit interne, evaluation des auditeurs internes et suivi des pa issus des audits realises\n",
      "-redaction, verification des sop\n",
      "-gestion des documents relatifs au depot d'un nouveau produit\n",
      "-mise au point et validation des methodes analytiques.\n",
      "La principale mission accordee dans ce stage qui a duree 02 mois est le controle de la matiere premiere des son arrivee. cela a permis a lentreprise d'assurer la qualite des matieres premieres utilisees afin de garantir l'efficacite de ses produits.\n",
      "-maitrise des outils informatique world, excel, powerpoint ,outlook, spectrum.\n",
      "-maitrise du logiciel qualite qualipro xl.\n",
      "-mise en place et suivi des kpi\n",
      "-veuille au respect de la data integrity\n",
      "Neapolis pharma, groupe medis\n",
      "-gestion et classement des courriers officiels des autorites competentes\n",
      "-connaissance pratique des normes bpf, bpl, usp, ph.euro.\n",
      "-assurer la formation continue du personnel sur les sop internes , les normes, les referentiels...\n",
      "-validation et verifications des bat\n",
      "Controle des matieres premieres et des aliments.\n",
      "-gestion des retours\n",
      "-realisation des cercles qualite\n",
      "-gestion du personnel elaboration des plans d'habilitation des personnes nouvellement recrutees\n",
      "-participation a des inspections gmp eur\n",
      "Responsable documentation qualite\n",
      "-coordination export\n",
      "-gestion des reclamations clients / fournisseurs\n",
      "-controle analytique des matieres premieres et produits finis.\n",
      "-realisation et suivi des investigation\n",
      "Projet de fin d'annee\n",
      "-participation a l'amelioration continue au seins des sites de production ( process, systeme qualite, securite, hygiene..)\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "print(clean_text(df[\"Experience\"][0],\"Experience\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dce5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79128868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85681d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
